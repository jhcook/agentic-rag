# Copy this file to `.env` and adjust values to override defaults.

EMBED_MODEL_NAME=sentence-transformers/paraphrase-MiniLM-L3-v2  # Hugging Face identifier for the embedding model
LLM_MODEL_NAME=ollama/llama3.2:1b  # LiteLLM/Ollama completion model name
ASYNC_LLM_MODEL_NAME=llama3.2:1b  # Model name for AsyncClient-based chat calls (no provider prefix)
OLLAMA_API_BASE=http://127.0.0.1:11434  # Base URL where `ollama serve` is listening
RAG_DB=./cache/rag_store.jsonl  # Path to the persisted document store
RAG_DEBUG_MODE=false  # Set to 'true' to skip expensive embedding operations for testing/development

MAX_MEMORY_MB=4096  # Soft memory ceiling for http_server; 75% of system memory if unset
MCP_PATH=/mcp  # HTTP path for the MCP transport
MCP_HOST=127.0.0.1  # Host/IP for http_server
MCP_PORT=8000  # Port for http_server
